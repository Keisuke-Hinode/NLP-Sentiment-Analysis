{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "感情分析（ML-Ask）",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iPiTS5BOgaY"
      },
      "source": [
        "# written by Keisuke Hinode（hinode@rikkyo.ac.jp）\n",
        "# See also https://github.com/Keisuke-Hinode/NLP-Sentiment-Analysis "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boHODSSHO5rj"
      },
      "source": [
        "# テキストファイルをアップロードする\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL3D4_awTZCX"
      },
      "source": [
        "#都合により、file_data1と2で同じものを指定\n",
        "file_data1 = open(\"text.csv\",\"r\",encoding=\"utf-8\")\n",
        "file_data2 = open(\"text.csv\",\"r\",encoding=\"utf-8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYZyLUOXj8xi"
      },
      "source": [
        "# MeCabのインストールする\n",
        "!apt install mecab libmecab-dev mecab-ipadic-utf8\n",
        "!pip install mecab-python3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISwex7dddfPs"
      },
      "source": [
        "# mecab-ipadic-NEologdのインストールする\n",
        "!apt install git make curl xz-utils file\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a\n",
        "!ln -s /etc/mecabrc /usr/local/etc/mecabrc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7u43cJKO5mu"
      },
      "source": [
        "# ML-Askをインストールする\n",
        "# Python版の実装（pymlask）を使う\n",
        "!pip install  pymlask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qHZXp4EQKCV"
      },
      "source": [
        "ポジティブ・ネガティブ分析"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_93JHsPT4y2"
      },
      "source": [
        "# 参考：https://qiita.com/masahiro54/items/e2186ec7ea8d91b84187\n",
        "# および：https://qiita.com/hnishi/items/0d32a778e375a99aff13\n",
        "import mlask\n",
        "import subprocess\n",
        "\n",
        "cmd='echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
        "path = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
        "                           shell=True).communicate()[0]).decode('utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXaA7TcVkhT5"
      },
      "source": [
        "emotion_analyzer = mlask.MLAsk('-d {0}'.format(path))\n",
        "#初期化\n",
        "senryu =[]\n",
        "positive_count = 0\n",
        "negative_count = 0\n",
        "neutral_count = 0\n",
        "exception_count = 0\n",
        "for line in file_data1:\n",
        "    #改行コードを削除して、感情分析を行います。\n",
        "    emotion_senryu = emotion_analyzer.analyze(line.replace(\"\\n\",\"\"))\n",
        "    #orientationが設定されない場合があるので、try exceptで囲っています。\n",
        "    try:\n",
        "        if  \"POSITIVE\" in emotion_senryu['orientation']:\n",
        "            positive_count += 1\n",
        "            #print(\"POSITIVE\") ←デバッグ用です。\n",
        "            #print(line)\n",
        "        elif \"NEGATIVE\" in emotion_senryu['orientation']:\n",
        "            negative_count += 1\n",
        "            #print(\"NEGATIVE\")\n",
        "            #print(line)\n",
        "        else:\n",
        "            neutral_count += 1\n",
        "    #判定不能の場合はexception_countに割り振ります。\n",
        "    except:\n",
        "        exception_count += 1\n",
        "#トータルの件数\n",
        "print(\"ネガティブ：\" + str(negative_count))\n",
        "print(\"ポジティブ：\" + str(positive_count))\n",
        "print(\"ニュートラル：\" + str(neutral_count))\n",
        "print(\"例外：\"+str(exception_count))\n",
        "\n",
        "#10万行で約2分30秒（GPU不使用）\n",
        "#80万行で約12分(GPU使用)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMbnvOMXSABE"
      },
      "source": [
        "10分類\n",
        "\n",
        "入力されたテキストに10種類の感情を割り当てる\n",
        "\n",
        "喜・怒・昂・哀・好・怖・安・厭・驚・恥"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J33NvK-gQS0h"
      },
      "source": [
        "ML-Askによる10分類の感情分析を用いた先行研究は、以下の2つが比較的わかりやすい\n",
        "\n",
        "[鳥海・榊・吉田（2020）](https://www.jstage.jst.go.jp/article/tjsai/35/4/35_F-K45/_pdf)\n",
        "\n",
        "[笹原・奥田・五十嵐（2021）](https://www.jstage.jst.go.jp/article/pjsai/JSAI2021/0/JSAI2021_1D3OS3b04/_pdf)\n",
        "\n",
        "どちらも、分類された感情ごとにTF-IDFで特徴語を算出し、その感情をもたらした要因を考察している\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ztb79BN5VP4k"
      },
      "source": [
        "1. まずは10分類の数を出す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32sp_G-r8ZKX"
      },
      "source": [
        "import mlask\n",
        "import subprocess\n",
        "\n",
        "cmd='echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
        "path = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
        "                           shell=True).communicate()[0]).decode('utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPC0A4GbAbnk"
      },
      "source": [
        "emotion_analyzer = mlask.MLAsk('-d {0}'.format(path))\n",
        "#初期化\n",
        "senryu=[]\n",
        "iya_count = 0\n",
        "yorokobi_count = 0\n",
        "yasu_count = 0\n",
        "suki_count = 0\n",
        "aware_count = 0\n",
        "ikari_count = 0\n",
        "odoroki_count = 0\n",
        "takaburi_count = 0\n",
        "haji_count = 0\n",
        "kowa_count = 0\n",
        "exception_count = 0\n",
        "for line in file_data2:\n",
        " \n",
        "    emotion_senryu = emotion_analyzer.analyze(line.replace(\"\\n\",\"\"))\n",
        "\n",
        "    try:\n",
        "        if  'iya' in emotion_senryu ['representative']:\n",
        "            iya_count += 1\n",
        "        \n",
        "        elif 'yorokobi' in emotion_senryu ['representative']:\n",
        "            yorokobi_count += 1\n",
        "\n",
        "        elif 'yasu' in emotion_senryu ['representative']:\n",
        "            yasu_count += 1\n",
        "        \n",
        "        elif 'suki' in emotion_senryu ['representative']:\n",
        "            suki_count += 1\n",
        "        \n",
        "        elif 'aware' in emotion_senryu ['representative']:\n",
        "            aware_count += 1\n",
        "        \n",
        "        elif 'ikari' in emotion_senryu ['representative']:\n",
        "            ikari_count += 1\n",
        "        \n",
        "        elif 'odoroki' in emotion_senryu ['representative']:\n",
        "            odoroki_count += 1\n",
        "        \n",
        "        elif 'takaburi' in emotion_senryu ['representative']:\n",
        "            takaburi_count += 1\n",
        "        \n",
        "        elif 'haji' in emotion_senryu ['representative']:\n",
        "            haji_count += 1\n",
        "\n",
        "        elif 'kowa' in emotion_senryu ['representative']:\n",
        "            kowa_count += 1\n",
        "\n",
        "    #判定不能の場合はexception_countに割り振ります。\n",
        "    except:\n",
        "        exception_count += 1\n",
        "#トータルの件数\n",
        "print(\"好：\" + str(suki_count))\n",
        "print(\"喜：\" + str(yorokobi_count))\n",
        "print(\"安：\" + str(yasu_count))\n",
        "print(\"昂：\" + str(takaburi_count))\n",
        "print(\"驚：\" + str(odoroki_count))\n",
        "print(\"怒：\" + str(ikari_count))\n",
        "print(\"厭：\" + str(iya_count))\n",
        "print(\"恥：\" + str(haji_count))\n",
        "print(\"哀：\" + str(aware_count))\n",
        "print(\"怖：\" + str(kowa_count))\n",
        "print(\"例外：\"+str(exception_count))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEd1kxxvVUFx"
      },
      "source": [
        "2. 次に、それぞれのテキストに感情を割り当てていく"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7h290KvVaK2"
      },
      "source": [
        "#pandasを使う\n",
        "#予め\"（ダブルクオーテーション）をエディタで削除してからでないと、1行1投稿にならないことがあるので注意\n",
        "\n",
        "import pandas as pd\n",
        "text = pd.read_csv(\"text.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIMHMieSWHOD"
      },
      "source": [
        "print(len(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuizJGjdYBel"
      },
      "source": [
        "text.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ehEh7Jyha6K"
      },
      "source": [
        "import mlask\n",
        "import subprocess\n",
        "\n",
        "cmd='echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
        "path = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
        "                           shell=True).communicate()[0]).decode('utf-8')\n",
        "                           \n",
        "emotion_analyzer = mlask.MLAsk('-d {0}'.format(path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGWtUsA7ZVD-"
      },
      "source": [
        "#動作テスト\n",
        "emotion_analyzer.analyze(\"彼のことは嫌いではない\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUCevU2qZVBK"
      },
      "source": [
        "#このように、出力される結果が見にくいので、以下のように処理"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yl38Exrha1y"
      },
      "source": [
        "#applymapで1行ずつ処理をしていく\n",
        "#結果を新しいデータフレームに格納\n",
        "result = text.applymap(emotion_analyzer.analyze)\n",
        "\n",
        "\n",
        "#処理時間はこれまでと同程度"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJI1UspAaQP3"
      },
      "source": [
        "print(len(result))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEsMo7FXYDqR"
      },
      "source": [
        "result.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga28i0q0CPIM"
      },
      "source": [
        "#以下、半ば強引にデータフレームの中で結果を整形する\n",
        "result = result.rename(columns={'内容': 'emotion'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4td3hmXbKhY"
      },
      "source": [
        "result['emotion'] = result['emotion'] .astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOpfAGSWayfJ"
      },
      "source": [
        "result[\"emotion2\"] = result[\"emotion\"].replace(\"(.*)(?=emotion)\", \"\", regex=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjZent7ra3Qg"
      },
      "source": [
        "result.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwstB1Q49b7-"
      },
      "source": [
        "result[\"emotion2\"] = result[\"emotion2\"].replace(\"(?<=})(.*)\", \"\", regex=True)\n",
        "result[\"emotion2\"] = result[\"emotion2\"].str.replace(\"}$\", \"\", regex=True)\n",
        "result[\"emotion2\"] = result[\"emotion2\"].str.replace('{', '', regex=True)\n",
        "result[\"emotion2\"] = result[\"emotion2\"].replace('[!\"#$%&\\'\\\\\\\\()*+,-./:;<=>?@\\\\^_`{|}~「」〔〕“”〈〉『』【】＆＊・（）＄＃＠。、？！｀＋￥％]', \"\", regex=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTli76HIbecW"
      },
      "source": [
        "result.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXELb2RgbftF"
      },
      "source": [
        "#ここで、もとの投稿が入ったデータフレーム（text）と結果のデータフレーム（result[emotion2]）にそれぞれ行の番号を振って、それをキーに結合する\n",
        "serial_num = pd.RangeIndex(start=1, stop=len(text.index) + 1, step=1)\n",
        "text['No'] = serial_num\n",
        "serial_num = pd.RangeIndex(start=1, stop=len(result.index) + 1, step=1)\n",
        "result['No'] = serial_num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kILSwYu-7BdA"
      },
      "source": [
        "analysis = pd.merge(text, result[[\"emotion2\", \"No\"]], on=\"No\", how=\"outer\")\n",
        "analysis.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StPgubk-Wf5v"
      },
      "source": [
        "del analysis[\"No\"]\n",
        "analysis = analysis.rename(columns={'emotion2': 'emotion'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ikzq3PvYcxH"
      },
      "source": [
        "analysis.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggdmQRdgFOrP"
      },
      "source": [
        "#感情無しの行は行ごと削除しても良い\n",
        "#analysis = analysis[~analysis['emotion'].str.contains('感情無し')]\n",
        "\n",
        "#emotion列の不要な部分を消す\n",
        "analysis['emotion'] = analysis['emotion'].str.replace('emotion defaultdictclass list', '', regex=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySlIOo7vhlXp"
      },
      "source": [
        "#結果の感情成分を漢字に変換\n",
        "analysis['emotion'] = analysis['emotion'].str.replace('suki','好', regex=True)\n",
        "analysis['emotion'] = analysis['emotion'].str.replace('yorokobi','喜', regex=True)\n",
        "analysis['emotion'] = analysis['emotion'].str.replace('yasu','安', regex=True)\n",
        "analysis['emotion'] = analysis['emotion'].str.replace('takaburi','昂', regex=True)\n",
        "analysis['emotion'] = analysis['emotion'].str.replace('odoroki','驚', regex=True)\n",
        "analysis['emotion'] = analysis['emotion'].str.replace('ikari','怒', regex=True)\n",
        "analysis['emotion'] = analysis['emotion'].str.replace('iya','厭', regex=True)\n",
        "analysis['emotion'] = analysis['emotion'].str.replace('haji','恥', regex=True)\n",
        "analysis['emotion'] = analysis['emotion'].str.replace('aware','哀', regex=True)\n",
        "analysis['emotion'] = analysis['emotion'].str.replace('kowa','怖', regex=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoLCMFmAFOnB"
      },
      "source": [
        "#最終結果\n",
        "analysis.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B79aVIAXhleG"
      },
      "source": [
        "analysis.to_csv(\"result.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H3jd_T7ZoZz"
      },
      "source": [
        "課題\n",
        "\n",
        "\n",
        "*   精度があまり高くない（3割くらいしか分類出来ない）\n",
        "*   ベースの辞書（[『感情表現辞典』](https://www.amazon.co.jp/%E6%84%9F%E6%83%85%E8%A1%A8%E7%8F%BE%E8%BE%9E%E5%85%B8-%E4%B8%AD%E6%9D%91-%E6%98%8E/dp/4490103395)）が古い\n",
        "\n",
        "\n",
        "※ どの感情表現がどの分類に対応するか、[感情表現の一覧を作者のHPからcsvでダウンロードできる](http://arakilab.media.eng.hokudai.ac.jp/~ptaszynski/repository/mlask.htm)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYeiDEv7bgy4"
      },
      "source": [
        "しかし\n",
        "\n",
        "*  ポジネガや10分類で結果がわかりやすい\n",
        "*  感情分析（感情推定）自体、難しい技術であり、現状使いやすいものが少ない（[参考：鳥海さん「感情抽出は技術的に非常に難しい」](https://news.yahoo.co.jp/byline/toriumifujio/20200720-00188646)）\n",
        "*  単純に10分類するのでは無く、分類した上で時系列での変化や比較をすれば、より訴求力のある結果になる\n",
        "*  もとの感情表現のcsvを自分で更新すれば、アレンジした分析ができる（Pythonで実装するのが難しくなるが）\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}